### demo codes for "Adversarial Cross-modal Retrieval (ACMR)"

To run the demo: 

    # Wikipedia dataset
    python train_adv_crossmodal_simple_wiki.py # with contrastive loss
    python train_adv_crossmodal_triplet_wiki.py # with triplet loss

We have prepared the data in the "./data" folder. If you have any question, please contact Bokun Wang at csbkwang@gmail.com. 

Note: The codes were modified from the implementation of "Unsupervised Cross-modal Retrieval through Adversarial Learning", written by <a href="https://www.linkedin.com/in/ritsu1228/">Li He</a>. If you use the codes, please cite the following two papers: 

[1]  Li He, Xing Xu, Huimin Lu, Yang Yang, Fumin Shen and Heng Tao Shen.  "Unsupervised Cross-modal Retrieval through Adversarial Learning". IEEE International Conference on Multimedia and Expo (ICME), 2017. 

[2]  Bokun Wang, Yang Yang, Xing Xu, Alan Hanjalic, and Heng Tao Shen. "Adversarial Cross-Modal Retrieval". In Proceedings of 25th ACM International Conference on Multimedia (ACM MM), 2017.
